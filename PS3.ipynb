{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "891ee364",
   "metadata": {},
   "source": [
    "## Problem set 3\n",
    "\n",
    "## Name: [TODO]\n",
    "\n",
    "## Link to your PS3 github repo: [TODO]\n",
    "\n",
    "### Problem 0 \n",
    "\n",
    "-2 points for every missing green OK sign. \n",
    "\n",
    "Make sure you are in the DATA1030 environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf77c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from packaging.version import parse as Version\n",
    "from platform import python_version\n",
    "\n",
    "OK = '\\x1b[42m[ OK ]\\x1b[0m'\n",
    "FAIL = \"\\x1b[41m[FAIL]\\x1b[0m\"\n",
    "\n",
    "try:\n",
    "    import importlib\n",
    "except ImportError:\n",
    "    print(FAIL, \"Python version 3.12.10 is required,\"\n",
    "                \" but %s is installed.\" % sys.version)\n",
    "\n",
    "def import_version(pkg, min_ver, fail_msg=\"\"):\n",
    "    mod = None\n",
    "    try:\n",
    "        mod = importlib.import_module(pkg)\n",
    "        if pkg in {'PIL'}:\n",
    "            ver = mod.VERSION\n",
    "        else:\n",
    "            ver = mod.__version__\n",
    "        if Version(ver) == Version(min_ver):\n",
    "            print(OK, \"%s version %s is installed.\"\n",
    "                  % (lib, min_ver))\n",
    "        else:\n",
    "            print(FAIL, \"%s version %s is required, but %s installed.\"\n",
    "                  % (lib, min_ver, ver))    \n",
    "    except ImportError:\n",
    "        print(FAIL, '%s not installed. %s' % (pkg, fail_msg))\n",
    "    return mod\n",
    "\n",
    "\n",
    "# first check the python version\n",
    "pyversion = Version(python_version())\n",
    "\n",
    "if pyversion >= Version(\"3.12.10\"):\n",
    "    print(OK, \"Python version is %s\" % pyversion)\n",
    "elif pyversion < Version(\"3.12.10\"):\n",
    "    print(FAIL, \"Python version 3.12.10 is required,\"\n",
    "                \" but %s is installed.\" % pyversion)\n",
    "else:\n",
    "    print(FAIL, \"Unknown Python version: %s\" % pyversion)\n",
    "\n",
    "    \n",
    "print()\n",
    "requirements = {'numpy': \"2.2.5\", 'matplotlib': \"3.10.1\",'sklearn': \"1.6.1\", \n",
    "                'pandas': \"2.2.3\",'xgboost': \"3.0.0\", 'shap': \"0.47.2\", \n",
    "                'polars': \"1.27.1\", 'seaborn': \"0.13.2\"}\n",
    "\n",
    "# now the dependencies\n",
    "for lib, required_version in list(requirements.items()):\n",
    "    import_version(lib, required_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0837d2-31a4-4d7e-b842-70bb3a83f18a",
   "metadata": {},
   "source": [
    "## Problem 1: EDA and visualizations\n",
    "\n",
    "### Problem 1a: EDA (5 points)\n",
    "\n",
    "One of the datasets we will be working with this semester is the kaggle house price dataset. The goal of PS3 is to use this dataset to practice dataframe manipulations and perform EDA. The dataset, and its description, are located in the `data` folder.\n",
    "\n",
    "Carefully read the dataset description. Whenever you work with a dataset, it is highly recommended that you prepare a similar description if it is not readily available. Specific things to note:\n",
    "\n",
    "- each feature is described in full detail,\n",
    "- the meaning of continuous features is explained and their unit is provided (e.g., lot size is measured in square feet),\n",
    "- each category in a categorical or ordinal feature is spelled out and explained.\n",
    "\n",
    "Answer the following EDA-related questions. \n",
    "\n",
    "The sequence of questions here are typical things to ask when you perform EDA on a new dataset. First, you always want to know how many data points and features you have, and whether they are continuous, ordinal, or categorical. You should then take a closer look at the target variable. We will study the properties of the features and the relationships between the features and the target variable in 1b."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f562ebe-238f-44ca-ae68-cc8af7b75209",
   "metadata": {},
   "source": [
    "**Q0** First, read the data into a data frame and display the columns of the data frame below. You might encounter error messages and other issues along the way. Please diagnose and resolve them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72749e8d-1686-4e8c-96f7-82431d30692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6f15de-9194-461c-8e58-eaff67f6324c",
   "metadata": {},
   "source": [
    "**Q1** How many rows and columns do we have in the dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fa2488-c0cf-41fc-8aa9-6ca32e5b4add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f46d54-2d90-467a-9ddb-a3ccf2af2acc",
   "metadata": {},
   "source": [
    "**Q2** What are the data types of the columns? Make sure that the output is not truncated and you see the type of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3f8a2b-d5bf-45bd-b8fd-d32fa0e8ab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631a89db-6caf-4dbf-b3fb-42ce8c3d56d9",
   "metadata": {},
   "source": [
    "**Q3** The ML target variable in this dataset is the sale price. We will develop ML pipelines to predict this variable based on the other features.\n",
    "\n",
    "Is this column continuous or categorical? Please use .describe or .value_counts to take a quick look at this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b1f833-7ce0-4eb8-a9fb-480dfc70bd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970708b8-b2ca-415a-8fff-748f259207f3",
   "metadata": {},
   "source": [
    "**Q4** Visualize the target variable. Don't forget the axis labels and graph title. Make sure to use appropriate arguments to best display the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58094eb-ce6f-4aa0-b38b-dc3a7e54fa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb5628d-2372-4b82-b019-0354156cf1be",
   "metadata": {},
   "source": [
    "### Problem 1b: visualization (10 points)\n",
    "\n",
    "Find one continuous, one ordinal, and one categorical feature that strongly correlates with the sale price. Create figures that illustrate your selected features and the sale price.\n",
    "\n",
    "Don't forget to add axis labels and titles, and find apropriate arguments. Write figure captions to explain what the figure shows.\n",
    "\n",
    "If you know how to quantitatively assess correlation strengths between variables, feel free to use those techniques. Qualitative/visual assessment also works for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34c4850-add1-4eec-bb98-298fa5edcc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab243010-95e7-433f-a0b6-7e1e11141b04",
   "metadata": {},
   "source": [
    "## Problem 2: basic splitting strategy (15 points)\n",
    "\n",
    "Write a general function that performs basic splitting on a dataset, while also conducting integrity tests on both its inputs and outputs. The function is called basic_split, it is outlined in the cell below. It takes the following arguments as inputs: feature matrix (X), a target variable (y), train_size, val_size, test_size, and random_state. The output of the function should be: X_train, y_train, X_val, y_val, X_test, y_test, the three sets split according to the train, val, test sizes.\n",
    "\n",
    "This function is general purpose, you'll be able to reuse it for any project if you want to perform basic split on your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359129f3-75e4-4c59-b2a8-841ca49c844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_split(feature_matrix,target_variable,train_size = 0.6,val_size=0.2,test_size=0.2,random_state=42):\n",
    "    '''\n",
    "    Split dataframes (feature matrix X and target variable y) into random train, validation and test sets\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    \n",
    "    feature_matrix: a dataframe that contains your feature matrix\n",
    "    target_variable: a series that contains your target variable\n",
    "    train_size: a float between 0.0 and 1.0, it represents the proportion\n",
    "        of the dataset to include in the training set\n",
    "    val_size: a float between 0.0 and 1.0, it represents the proportion\n",
    "        of the dataset to include in the validation set\n",
    "    test_size: a float between 0.0 and 1.0, it represents the proportion\n",
    "        of the dataset to include in the test set\n",
    "    random_state: an int, it controls the shuffling applied to the data \n",
    "        before applying the split\n",
    "\n",
    "    NOTE: train_size+val_size+test_size must be equal to 1.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        a tuple containing the train, validation, and test sets\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "\n",
    "    >>> import numpy as np\n",
    "    >>> from sklearn.model_selection import train_test_split\n",
    "    >>>\n",
    "    >>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
    "    >>>\n",
    "    >>> X_train, y_train, X_val, y_val, X_test, y_test = basic_split(X,y)\n",
    "\n",
    "    '''\n",
    "\n",
    "    # ***************************\n",
    "    # TODO: test the inputs first\n",
    "    # ***************************\n",
    "    # write an if statement to perform each of these checks\n",
    "    # Important: raise a ValueError with a descriptive error message if something is off\n",
    "    # call basic_split with incorrect arguments to make sure all of the tests work as intended!\n",
    "    \n",
    "    # test 1: if feature_matrix is not a dataframe (pandas or polars), raise ValueError\n",
    "\n",
    "    # test 2: if the target-variable is not a series (pandas or polars), raise ValueError\n",
    "\n",
    "    # test 3: if the number of rows in feature_matrix is not equal to the length of target_variable, raise a ValueError\n",
    "\n",
    "    # test 4: if train_size is less than 0.0 or larger than 1.0, raise ValueError\n",
    "\n",
    "    # test 5: if val_size is less than 0.0 or larger than 1.0, raise ValueError\n",
    "    \n",
    "    # test 6: if test_size is less than 0.0 or larger than 1.0, raise ValueError\n",
    "\n",
    "    # test 7: if train_size+val_size+test_size is not equal to 1.0, raise ValueError\n",
    "\n",
    "    # test 8: if random state is not an integer, raise ValueError\n",
    "\n",
    "    \n",
    "    # **************************************\n",
    "    # TODO: implement the splitting strategy\n",
    "    # **************************************\n",
    "    # as we discussed in class, use sklearn's train_test_split twice\n",
    "\n",
    "\n",
    "    # **********************\n",
    "    # TODO: test the outputs\n",
    "    # **********************\n",
    "    # same as above, write an if statement to perform each of these checks\n",
    "    # raise a ValueError with a descriptive error message if something is off.\n",
    "    \n",
    "    # test 1: the number of rows in X_train divided by the number of rows in X should be close to train_size\n",
    "    # think why we sometimes cannot achieve exact equality \n",
    "    # and how you should express this as a condition in the if statement\n",
    "\n",
    "    # test 2: the number of rows in X_val divided by the number of rows in X should be close to val_size\n",
    "    \n",
    "    # test 3: the number of rows in X_test divided by the number of rows in X should be close to test_size\n",
    "\n",
    "    # test 4: make sure that the length of y_train, y_val, y_test is equal to \n",
    "    # the number of rows in X_train, X_val, X_test, respectively\n",
    "\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "# Call the function and preform tests here\n",
    "# test 1: Apply the function to the house price dataset from problem 1 with train_size = 0.6, val_size = 0.2, and test_size = 0.2. \n",
    "\n",
    "# test 2: Print out the head of X_train, X_val, and X_test. \n",
    "    \n",
    "# test 3: Make sure that you get the same points in each set every time you rerun the cell (a.k.a., test for reproducability).\n",
    "\n",
    "# test 4: Try a couple of other train, val, test sizes here. make sure to test the possible extreme values! \n",
    "\n",
    "\n",
    "# notice how most of the lines in basic_split are about testing the inputs and outputs and\n",
    "# testing the inputs ensures that the user correctly calls the function. if they do not, a descriptive error message is returned.\n",
    "# testing the outputs ensures that your code correctly performs the intended operation anticipating edge cases and potential issues.\n",
    "# this is pretty typical in software engineering and this is the key to writing reusable code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8743d3b3-e9ff-4b39-8e65-a460a2529a0a",
   "metadata": {},
   "source": [
    "# Problem 3: kfold splitting (20 points)\n",
    "\n",
    "Write a function that performs kfold splitting. We provided the input arguments and the header of the function. You need test the inputs, implement the algorithm, and test the outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e19fb6-0c29-4aa0-a31f-3cb02b384d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_kfold(feature_matrix,target_variable, k = 5, shuffle = True, random_state = 42):\n",
    "    '''\n",
    "    Split dataframes (feature matrix X and target variable y) into `k` number of equal size folds.\n",
    "    One fold is used as the test set.\n",
    "    Iterate over the remaining k-1 folds. Fold i is used as the validation set,\n",
    "    the remaining folds are used as the training set.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    \n",
    "    feature_matrix: a dataframe that contains your feature matrix\n",
    "    target_variable: a series that contains your target variable\n",
    "    k: an int, the number of folds\n",
    "    shuffle: boolean variable. If True, the feature matrix and the target variable are shuffled\n",
    "        before the folds are created to randomize the sets\n",
    "    random_state: an int, it controls the shuffling applied to the data   \n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        one test set and a list with `k-1` elements containing tuples of the train and validation sets\n",
    "\n",
    "    >>> import numpy as np\n",
    "    >>> from sklearn.model_selection import train_test_split\n",
    "    >>>\n",
    "    >>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
    "    >>>\n",
    "    >>> X_test, y_test, train_val_sets = basic_kfold(X,y)\n",
    "\n",
    "    '''\n",
    "    # one of the outputs, it will contain the train and validation sets\n",
    "    train_val_sets = []\n",
    "\n",
    "    # **********************\n",
    "    # TODO: test the inputs!\n",
    "    # **********************\n",
    "    # test each of the input arguments. consider their types and what values are possible as you come up with the tests\n",
    "    # come up with at least 8 tests\n",
    "    # among other things, consider what the smallest and largest k we can have\n",
    "\n",
    "    \n",
    "    # **************************************\n",
    "    # TODO: implement the splitting strategy\n",
    "    # **************************************\n",
    "    # you can use numpy, pandas or polars. do not use sklearn here!\n",
    "\n",
    "\n",
    "    # ***********************\n",
    "    # TODO: test the outputs!\n",
    "    # ***********************    \n",
    "    # test 1: check whether each point is in exactly one set (no point is duplicated and no point is left out)\n",
    "    \n",
    "    # test 2: check whether you preserve the row-wise alignment between the feature matrix and the target variable in each set\n",
    "    # hint: for row-wise alignment, it may be useful to note that row indices do not change when subsetting dfs. \n",
    "    # i.e. if a row is index id 10 in dataframe 1, it is still given the index id of 10 in a subsetted df.\n",
    "    \n",
    "    # test 3: check whether the order of the columns is the same in each set.\n",
    "    \n",
    "    # test 4: perform output tests similar to those in basic_split\n",
    "    \n",
    "    \n",
    "    return X_test, y_test, train_val_sets\n",
    "\n",
    "################################################\n",
    "# TODO: call the function and preform tests here\n",
    "################################################\n",
    "# test 1: Apply the function to the house price dataset from problem 1 with 4 folds. \n",
    "\n",
    "# test 2: Print out the head of the sets.\n",
    "\n",
    "# test 3: Make sure that you get the same points in each set every time you rerun the cell (a.k.a., test for reproducability).\n",
    "\n",
    "# test 4: Try a couple of other `k` values. test the extreme values!\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
